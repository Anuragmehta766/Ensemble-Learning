{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JfZpb3vX0hX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ensemble Learning\n"
      ],
      "metadata": {
        "id": "K0MEmVfF0lax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.What is Ensemble Learning in machine learning? Explain the key idea behind it."
      ],
      "metadata": {
        "id": "Kd6crJJy0nD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble learning is a powerful machine learning technique that combines the predictions of multiple individual models to improve overall performance and robustness. The key idea behind it is that by aggregating the outputs of several diverse models, you can achieve better results than any single model could achieve on its own. This is often because different models capture different aspects of the data, and their combined insights can lead to a more accurate and generalized prediction. Think of it like getting advice from a group of experts rather than just one – the collective wisdom is often more reliable."
      ],
      "metadata": {
        "id": "RzCXLGGE0v4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.What is the difference between Bagging and Boosting?"
      ],
      "metadata": {
        "id": "AXTgioM104uM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "533cdde9"
      },
      "source": [
        "Bagging and Boosting are two popular techniques in ensemble learning, but they differ in how they combine individual models and address errors:\n",
        "\n",
        "**Bagging (Bootstrap Aggregating):**\n",
        "\n",
        "*   **Parallel Processing:** Bagging trains multiple models independently and in parallel on different bootstrap samples (random subsets with replacement) of the original training data.\n",
        "*   **Variance Reduction:** The primary goal of bagging is to reduce variance, which is the sensitivity of a model to small changes in the training data. By averaging or voting on the predictions of multiple models trained on different subsets, the overall model becomes more stable and less prone to overfitting.\n",
        "*   **Examples:** Random Forest is a well-known example of a bagging algorithm.\n",
        "\n",
        "**Boosting:**\n",
        "\n",
        "*   **Sequential Processing:** Boosting trains models sequentially, where each subsequent model focuses on correcting the errors made by the previous models. It gives more weight to the misclassified instances.\n",
        "*   **Bias and Variance Reduction:** Boosting primarily aims to reduce bias, which is the tendency of a model to systematically underpredict or overpredict. By iteratively focusing on difficult instances, boosting can create a strong learner from a series of weak learners. It can also reduce variance.\n",
        "*   **Examples:** AdaBoost, Gradient Boosting Machines (GBM), and XGBoost are popular boosting algorithms.\n",
        "\n",
        "In summary, Bagging focuses on reducing variance by training models in parallel on bootstrapped data, while Boosting focuses on reducing bias by training models sequentially and emphasizing misclassified instances."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.What is bootstrap sampling and what role does it play in Bagging methodslike Random Forest?"
      ],
      "metadata": {
        "id": "aYZKRvJZ1EUd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c4be47d"
      },
      "source": [
        "### Bootstrap Sampling in Bagging\n",
        "\n",
        "Bootstrap sampling is a resampling technique used in Bagging methods like Random Forest. Here's how it works and its role:\n",
        "\n",
        "*   **What is Bootstrap Sampling?**\n",
        "    Bootstrap sampling involves creating multiple subsets (called bootstrap samples) from the original training dataset. Each bootstrap sample is created by randomly selecting instances from the original dataset **with replacement**. This means that some instances from the original dataset may appear multiple times in a single bootstrap sample, while others may not appear at all.\n",
        "\n",
        "*   **Role in Bagging (e.g., Random Forest):**\n",
        "    In Bagging, bootstrap sampling is crucial for creating diversity among the individual models (e.g., decision trees in a Random Forest). Here's why it's important:\n",
        "    *   **Creating diverse training sets:** By training each individual model on a different bootstrap sample, you ensure that each model sees a slightly different version of the data. This helps to reduce the correlation between the individual models' predictions.\n",
        "    *   **Reducing variance:** When you aggregate the predictions of multiple models trained on diverse datasets, the errors tend to cancel out, leading to a reduction in the overall variance of the ensemble model. This makes the ensemble model more stable and less prone to overfitting.\n",
        "\n",
        "In essence, bootstrap sampling provides the necessary variation in the training data for each model in a Bagging ensemble, which is key to achieving improved performance and robustness through variance reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.: What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?"
      ],
      "metadata": {
        "id": "Ig8HFmmr1O1F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21d74438"
      },
      "source": [
        "### Out-of-Bag (OOB) Samples and OOB Score\n",
        "\n",
        "**Out-of-Bag (OOB) Samples:**\n",
        "\n",
        "In Bagging methods like Random Forest, each individual model is trained on a bootstrap sample of the original data. Since bootstrap sampling is done with replacement, each bootstrap sample will contain approximately 63.2% of the original data, and the remaining instances (about 36.8%) are not included in that particular sample. These instances that are *not* used to train a specific model are called its **Out-of-Bag (OOB) samples**.\n",
        "\n",
        "**How is OOB Score Used for Evaluation?**\n",
        "\n",
        "The OOB samples provide a convenient way to evaluate the performance of a Bagging ensemble *without* the need for a separate validation set. Here's how it works:\n",
        "\n",
        "1.  For each instance in the original training dataset, identify the individual models in the ensemble for which this instance was an OOB sample.\n",
        "2.  Use these models to predict the outcome for that specific instance.\n",
        "3.  Aggregate the predictions from these models (e.g., by averaging for regression or voting for classification) to get an OOB prediction for that instance.\n",
        "4.  Compare the OOB prediction to the actual target value for that instance.\n",
        "\n",
        "By doing this for all instances in the original dataset, you can calculate an overall OOB score (e.g., accuracy for classification, mean squared error for regression). This OOB score serves as an estimate of the ensemble model's performance on unseen data, similar to how a score on a validation set would be used.\n",
        "\n",
        "**Benefits of using OOB score:**\n",
        "\n",
        "*   **Efficient:** It avoids the need to split the data into separate training and validation sets, allowing you to use all the data for training.\n",
        "*   **Unbiased:** Since the OOB samples were not used to train the models that are making the predictions, the OOB score provides an unbiased estimate of the model's generalization performance.\n",
        "\n",
        "In summary, OOB samples are the instances not included in a bootstrap sample for a particular model, and the OOB score is calculated by using these samples to evaluate the ensemble's performance, providing an efficient and unbiased estimate of its generalization ability."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.: Compare feature importance analysis in a single Decision Tree vs. a Random Forest."
      ],
      "metadata": {
        "id": "kvn9jAng1bP4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ef36daa"
      },
      "source": [
        "### Feature Importance Analysis: Single Decision Tree vs. Random Forest\n",
        "\n",
        "Feature importance is a measure of how much each feature contributes to the model's prediction. Here's a comparison of how it works in a single Decision Tree versus a Random Forest:\n",
        "\n",
        "**Single Decision Tree:**\n",
        "\n",
        "*   **How it's calculated:** Feature importance in a single decision tree is typically calculated based on how much the feature reduces impurity (like Gini impurity or entropy) at each split. Features that result in larger reductions in impurity are considered more important.\n",
        "*   **Interpretation:** The importance scores are specific to that single tree. A feature might appear very important in one tree but less so in another, depending on the specific data splits made.\n",
        "*   **Limitations:** Feature importance in a single tree can be unstable and highly influenced by small changes in the data or the tree's structure. It can also be biased towards features with many unique values.\n",
        "\n",
        "**Random Forest:**\n",
        "\n",
        "*   **How it's calculated:** In a Random Forest, feature importance is calculated by averaging the importance scores of each feature across all the individual decision trees in the forest. There are two common methods:\n",
        "    *   **Mean Decrease in Impurity (MDI):** This is the most common method. It calculates the average reduction in impurity contributed by each feature across all trees.\n",
        "    *   **Mean Decrease in Accuracy (MDA):** This method measures how much the model's accuracy decreases when a feature's values are randomly permuted. Features that cause a larger drop in accuracy are considered more important.\n",
        "*   **Interpretation:** The importance scores in a Random Forest are generally more stable and reliable than in a single tree because they are averaged over many trees. They provide a more robust estimate of the overall importance of each feature.\n",
        "*   **Benefits:** Random Forest feature importance is less prone to the limitations of single trees, such as instability and bias towards high-cardinality features (though some bias can still exist). It provides a more global view of feature importance across the dataset.\n",
        "\n",
        "**In Summary:**\n",
        "\n",
        "While both methods provide insights into feature importance, Random Forest feature importance is generally preferred because it is more stable, robust, and less sensitive to the specifics of a single tree. It provides a more reliable measure of the overall contribution of each feature to the ensemble's predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6.Write a Python program to:\n",
        "● Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        "\n",
        "● Train a Random Forest Classifier\n",
        "\n",
        "● Print the top 5 most important features based on feature importance scores.\n"
      ],
      "metadata": {
        "id": "-OfqJOGX1ofF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# Sort features by importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the top 5 most important features\n",
        "top_5_features = feature_importance_df.head(5)\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(top_5_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udHB6qyQ2clN",
        "outputId": "55010a49-ceef-42a3-a207-cbb5cb42a190"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "                 Feature  Importance\n",
            "23            worst area    0.139357\n",
            "27  worst concave points    0.132225\n",
            "7    mean concave points    0.107046\n",
            "20          worst radius    0.082848\n",
            "22       worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.: Write a Python program to:\n",
        "● Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "\n",
        "● Evaluate its accuracy and compare with a single Decision Tree"
      ],
      "metadata": {
        "id": "r8sp9DSK2lNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a single Decision Tree Classifier\n",
        "single_tree = DecisionTreeClassifier(random_state=42)\n",
        "single_tree.fit(X_train, y_train)\n",
        "\n",
        "# Train a Bagging Classifier using Decision Trees\n",
        "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
        "                                       n_estimators=10, random_state=42)\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the accuracy of the single Decision Tree\n",
        "single_tree_pred = single_tree.predict(X_test)\n",
        "single_tree_accuracy = accuracy_score(y_test, single_tree_pred)\n",
        "\n",
        "# Evaluate the accuracy of the Bagging Classifier\n",
        "bagging_pred = bagging_classifier.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "# Print the accuracies\n",
        "print(f\"Accuracy of a single Decision Tree: {single_tree_accuracy:.4f}\")\n",
        "print(f\"Accuracy of the Bagging Classifier: {bagging_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNw-A-SX2sBW",
        "outputId": "5ad9bd23-64ec-422b-d799-2f5c1ef23a3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of a single Decision Tree: 1.0000\n",
            "Accuracy of the Bagging Classifier: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8.Write a Python program to:\n",
        "● Train a Random Forest Classifier\n",
        "\n",
        "● Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "\n",
        "● Print the best parameters and final accuracy"
      ],
      "metadata": {
        "id": "ESZcTG0d20LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'n_estimators': [50, 100, 150, 200]\n",
        "}\n",
        "\n",
        "# Create a Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test data\n",
        "y_pred = best_rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f\"Accuracy of the tuned Random Forest Classifier: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1CP2aPz26iS",
        "outputId": "9992444e-6aa6-4e73-8081-6df7d8984688"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'max_depth': None, 'n_estimators': 150}\n",
            "Accuracy of the tuned Random Forest Classifier: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9.Write a Python program to:\n",
        "● Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset\n",
        "\n",
        "● Compare their Mean Squared Errors (MSE)"
      ],
      "metadata": {
        "id": "DxHNwcS83HSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Bagging Regressor using Decision Trees\n",
        "bagging_regressor = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42),\n",
        "                                     n_estimators=100, random_state=42)\n",
        "bagging_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "bagging_pred = bagging_regressor.predict(X_test)\n",
        "rf_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error for both models\n",
        "bagging_mse = mean_squared_error(y_test, bagging_pred)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "# Print the MSEs\n",
        "print(f\"Mean Squared Error (MSE) for Bagging Regressor: {bagging_mse:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE) for Random Forest Regressor: {rf_mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAPSSFdE3N2W",
        "outputId": "93774ccd-94a2-4c73-a1cf-95ee0644ac82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) for Bagging Regressor: 0.2568\n",
            "Mean Squared Error (MSE) for Random Forest Regressor: 0.2565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10.You are working as a data scientist at a financial institution to predict loan\n",
        "default. You have access to customer demographic and transaction history data.\n",
        "You decide to use ensemble techniques to increase model performance.\n",
        "Explain your step-by-step approach to:\n",
        "● Choose between Bagging or Boosting\n",
        "\n",
        "● Handle overfitting\n",
        "\n",
        "● Select base models\n",
        "\n",
        "● Evaluate performance using cross-validation\n",
        "\n",
        "● Justify how ensemble learning improves decision-making in this real-world\n",
        "context."
      ],
      "metadata": {
        "id": "zvIaF0cS3dPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Choose Between Bagging or Boosting\n",
        "\t•\tBagging (e.g., Random Forest): Reduces variance, good if base model overfits. Works well if individual models are high-variance (like Decision Trees).\n",
        "\t•\tBoosting (e.g., XGBoost, Gradient Boosting): Reduces bias, builds models sequentially focusing on hard-to-predict instances. Useful if base models underfit.\n",
        "\n",
        "Choice: Start with Boosting if your dataset is complex and you want higher accuracy in predicting defaults. Bagging (Random Forest) is an alternative for stability.\n",
        "\n",
        "\n",
        "\n",
        "2. Handle Overfitting\n",
        "\t•\tUse cross-validation to check performance consistency.\n",
        "\t•\tRegularization: Limit tree depth, min samples per leaf, learning rate (for boosting).\n",
        "\t•\tFeature selection: Drop irrelevant features to reduce noise.\n",
        "\t•\tEnsemble averaging: Bagging inherently reduces overfitting.\n",
        "\n",
        "\n",
        "\n",
        "3. Select Base Models\n",
        "\t•\tDecision Trees → high variance → good for Bagging/Boosting.\n",
        "\t•\tLogistic Regression → low variance → can be used in Stacking ensembles.\n",
        "\t•\tRandom Forest or Gradient Boosting as the main ensemble model.\n",
        "\n",
        "\n",
        "\n",
        "4. Evaluate Performance Using Cross-Validation\n",
        "\t•\tUse StratifiedKFold for imbalanced datasets (loan default often is imbalanced).\n",
        "\t•\tMetrics: Accuracy, ROC-AUC, F1-Score (since false negatives are costly in finance).\n",
        "\n",
        "\n",
        "\n",
        "5. Justification of Ensemble Learning\n",
        "\t•\tEnsemble methods combine multiple models → reduces variance (Bagging) or bias (Boosting).\n",
        "\t•\tIn financial decisions, predicting loan default accurately reduces non-performing loans and financial risk.\n",
        "\t•\tBoosting focuses on hard-to-predict defaulters → better risk assessment."
      ],
      "metadata": {
        "id": "G8YABesW4T1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "\n",
        "# Example: Load synthetic dataset (replace with real customer data)\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10,\n",
        "                           n_redundant=5, n_classes=2, weights=[0.7,0.3],\n",
        "                           random_state=42)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
        "                                                    test_size=0.2, random_state=42)\n",
        "\n",
        "# Choose Ensemble Model (Boosting)\n",
        "model = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1,\n",
        "                                   max_depth=3, random_state=42)\n",
        "\n",
        "# Cross-Validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
        "\n",
        "print(\"Cross-Validation ROC-AUC Scores:\", cv_scores)\n",
        "print(\"Mean CV ROC-AUC Score:\", cv_scores.mean())\n",
        "\n",
        "# Train final model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_proba)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"ROC-AUC:\", roc_auc)\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69gsdmCX4Y7y",
        "outputId": "db3878d0-c3ce-4d87-bcc7-6256355eb8e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation ROC-AUC Scores: [0.98958333 0.97637649 0.97517926 0.96322853 0.93822394]\n",
            "Mean CV ROC-AUC Score: 0.9685183110406325\n",
            "\n",
            "Test Set Performance:\n",
            "Accuracy: 0.95\n",
            "ROC-AUC: 0.9517631796202382\n",
            "F1-Score: 0.9122807017543859\n"
          ]
        }
      ]
    }
  ]
}